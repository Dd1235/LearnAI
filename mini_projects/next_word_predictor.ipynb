{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwuYHIPYfHcFn8Y0n9W1kx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dd1235/LearnAI/blob/main/mini_projects/next_word_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJH-z7srEDBF",
        "outputId": "fc15b8da-ca36-4751-d6e8-88abc17572d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "g8IqYXOdEXn8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"\n",
        "Today was a surprisingly productive day.\n",
        "I started by reviewing my notes from the Operating Systems lecture, and then I jumped straight into debugging a segmentation fault that had been bothering me since last night.\n",
        "Turned out, I was accessing memory after freeing it.\n",
        "Classic rookie mistake.\n",
        "Later, I spent some time working on my side project — an AI-powered college resource assistant.\n",
        "It's coming along nicely.\n",
        "I integrated a search functionality that uses cosine similarity to match user queries to existing lecture notes and textbook content.\n",
        "During lunch, I caught up with a few friends. We ended up discussing placement preparation strategies, how to approach DSA in a structured way, and whether doing a project on NLP using transformers could boost our resume visibility.\n",
        "In the afternoon, I decided to try out a new note-taking app on my iPad.\n",
        "It syncs perfectly with my MacBook and allows me to export annotated PDFs.\n",
        "I used it to mark up some slides for the DAA class, especially the part on dynamic programming and amortized analysis.\n",
        "Later in the evening, I had a short meeting with my hackathon team.\n",
        "We finalized the UI design for our ride-sharing optimization platform.\n",
        "We're building it using React for the frontend and Flask for the backend.\n",
        "After the meeting, I practiced some Leetcode problems.\n",
        "The one on \"Sliding Window Maximum\" took me longer than expected.\n",
        "I first tried a brute force solution with O(n*k), but then optimized it using a deque to get O(n) time complexity. It's satisfying when the optimized solution finally clicks.\n",
        "Before sleeping, I reviewed my semester goals.\n",
        "I still need to finish the Financial Statement Analysis project, polish my resume for the upcoming internships, and maybe try building a simple cloth simulation using C++ and SFML just for fun.\n",
        "I then did my night time skincare routine and wasted some time going through Instagram.\n",
        "Overall, I’m happy with how today went. I’ve realized that having a structured plan, combined with short bursts of focused work, is far more effective than spending hours in a distracted state. Hoping to continue this momentum tomorrow.\"\"\"\n"
      ],
      "metadata": {
        "id": "fnvbgy9pEa3N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da8NBnUUFMQm",
        "outputId": "48946e15-289f-4c15-969d-6ef1241d6698"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "qoQopubxFOsR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "vocab = {'<unk>':0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yllAtB0xFvWJ",
        "outputId": "15233c6b-a548-4024-8d43-94f9a09b5b06"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'today': 1,\n",
              " 'was': 2,\n",
              " 'a': 3,\n",
              " 'surprisingly': 4,\n",
              " 'productive': 5,\n",
              " 'day': 6,\n",
              " '.': 7,\n",
              " 'i': 8,\n",
              " 'started': 9,\n",
              " 'by': 10,\n",
              " 'reviewing': 11,\n",
              " 'my': 12,\n",
              " 'notes': 13,\n",
              " 'from': 14,\n",
              " 'the': 15,\n",
              " 'operating': 16,\n",
              " 'systems': 17,\n",
              " 'lecture': 18,\n",
              " ',': 19,\n",
              " 'and': 20,\n",
              " 'then': 21,\n",
              " 'jumped': 22,\n",
              " 'straight': 23,\n",
              " 'into': 24,\n",
              " 'debugging': 25,\n",
              " 'segmentation': 26,\n",
              " 'fault': 27,\n",
              " 'that': 28,\n",
              " 'had': 29,\n",
              " 'been': 30,\n",
              " 'bothering': 31,\n",
              " 'me': 32,\n",
              " 'since': 33,\n",
              " 'last': 34,\n",
              " 'night': 35,\n",
              " 'turned': 36,\n",
              " 'out': 37,\n",
              " 'accessing': 38,\n",
              " 'memory': 39,\n",
              " 'after': 40,\n",
              " 'freeing': 41,\n",
              " 'it': 42,\n",
              " 'classic': 43,\n",
              " 'rookie': 44,\n",
              " 'mistake': 45,\n",
              " 'later': 46,\n",
              " 'spent': 47,\n",
              " 'some': 48,\n",
              " 'time': 49,\n",
              " 'working': 50,\n",
              " 'on': 51,\n",
              " 'side': 52,\n",
              " 'project': 53,\n",
              " '—': 54,\n",
              " 'an': 55,\n",
              " 'ai-powered': 56,\n",
              " 'college': 57,\n",
              " 'resource': 58,\n",
              " 'assistant': 59,\n",
              " \"'s\": 60,\n",
              " 'coming': 61,\n",
              " 'along': 62,\n",
              " 'nicely': 63,\n",
              " 'integrated': 64,\n",
              " 'search': 65,\n",
              " 'functionality': 66,\n",
              " 'uses': 67,\n",
              " 'cosine': 68,\n",
              " 'similarity': 69,\n",
              " 'to': 70,\n",
              " 'match': 71,\n",
              " 'user': 72,\n",
              " 'queries': 73,\n",
              " 'existing': 74,\n",
              " 'textbook': 75,\n",
              " 'content': 76,\n",
              " 'during': 77,\n",
              " 'lunch': 78,\n",
              " 'caught': 79,\n",
              " 'up': 80,\n",
              " 'with': 81,\n",
              " 'few': 82,\n",
              " 'friends': 83,\n",
              " 'we': 84,\n",
              " 'ended': 85,\n",
              " 'discussing': 86,\n",
              " 'placement': 87,\n",
              " 'preparation': 88,\n",
              " 'strategies': 89,\n",
              " 'how': 90,\n",
              " 'approach': 91,\n",
              " 'dsa': 92,\n",
              " 'in': 93,\n",
              " 'structured': 94,\n",
              " 'way': 95,\n",
              " 'whether': 96,\n",
              " 'doing': 97,\n",
              " 'nlp': 98,\n",
              " 'using': 99,\n",
              " 'transformers': 100,\n",
              " 'could': 101,\n",
              " 'boost': 102,\n",
              " 'our': 103,\n",
              " 'resume': 104,\n",
              " 'visibility': 105,\n",
              " 'afternoon': 106,\n",
              " 'decided': 107,\n",
              " 'try': 108,\n",
              " 'new': 109,\n",
              " 'note-taking': 110,\n",
              " 'app': 111,\n",
              " 'ipad': 112,\n",
              " 'syncs': 113,\n",
              " 'perfectly': 114,\n",
              " 'macbook': 115,\n",
              " 'allows': 116,\n",
              " 'export': 117,\n",
              " 'annotated': 118,\n",
              " 'pdfs': 119,\n",
              " 'used': 120,\n",
              " 'mark': 121,\n",
              " 'slides': 122,\n",
              " 'for': 123,\n",
              " 'daa': 124,\n",
              " 'class': 125,\n",
              " 'especially': 126,\n",
              " 'part': 127,\n",
              " 'dynamic': 128,\n",
              " 'programming': 129,\n",
              " 'amortized': 130,\n",
              " 'analysis': 131,\n",
              " 'evening': 132,\n",
              " 'short': 133,\n",
              " 'meeting': 134,\n",
              " 'hackathon': 135,\n",
              " 'team': 136,\n",
              " 'finalized': 137,\n",
              " 'ui': 138,\n",
              " 'design': 139,\n",
              " 'ride-sharing': 140,\n",
              " 'optimization': 141,\n",
              " 'platform': 142,\n",
              " \"'re\": 143,\n",
              " 'building': 144,\n",
              " 'react': 145,\n",
              " 'frontend': 146,\n",
              " 'flask': 147,\n",
              " 'backend': 148,\n",
              " 'practiced': 149,\n",
              " 'leetcode': 150,\n",
              " 'problems': 151,\n",
              " 'one': 152,\n",
              " '``': 153,\n",
              " 'sliding': 154,\n",
              " 'window': 155,\n",
              " 'maximum': 156,\n",
              " \"''\": 157,\n",
              " 'took': 158,\n",
              " 'longer': 159,\n",
              " 'than': 160,\n",
              " 'expected': 161,\n",
              " 'first': 162,\n",
              " 'tried': 163,\n",
              " 'brute': 164,\n",
              " 'force': 165,\n",
              " 'solution': 166,\n",
              " 'o': 167,\n",
              " '(': 168,\n",
              " 'n': 169,\n",
              " '*': 170,\n",
              " 'k': 171,\n",
              " ')': 172,\n",
              " 'but': 173,\n",
              " 'optimized': 174,\n",
              " 'deque': 175,\n",
              " 'get': 176,\n",
              " 'complexity': 177,\n",
              " 'satisfying': 178,\n",
              " 'when': 179,\n",
              " 'finally': 180,\n",
              " 'clicks': 181,\n",
              " 'before': 182,\n",
              " 'sleeping': 183,\n",
              " 'reviewed': 184,\n",
              " 'semester': 185,\n",
              " 'goals': 186,\n",
              " 'still': 187,\n",
              " 'need': 188,\n",
              " 'finish': 189,\n",
              " 'financial': 190,\n",
              " 'statement': 191,\n",
              " 'polish': 192,\n",
              " 'upcoming': 193,\n",
              " 'internships': 194,\n",
              " 'maybe': 195,\n",
              " 'simple': 196,\n",
              " 'cloth': 197,\n",
              " 'simulation': 198,\n",
              " 'c++': 199,\n",
              " 'sfml': 200,\n",
              " 'just': 201,\n",
              " 'fun': 202,\n",
              " 'did': 203,\n",
              " 'skincare': 204,\n",
              " 'routine': 205,\n",
              " 'wasted': 206,\n",
              " 'going': 207,\n",
              " 'through': 208,\n",
              " 'instagram': 209,\n",
              " 'overall': 210,\n",
              " '’': 211,\n",
              " 'm': 212,\n",
              " 'happy': 213,\n",
              " 'went': 214,\n",
              " 've': 215,\n",
              " 'realized': 216,\n",
              " 'having': 217,\n",
              " 'plan': 218,\n",
              " 'combined': 219,\n",
              " 'bursts': 220,\n",
              " 'of': 221,\n",
              " 'focused': 222,\n",
              " 'work': 223,\n",
              " 'is': 224,\n",
              " 'far': 225,\n",
              " 'more': 226,\n",
              " 'effective': 227,\n",
              " 'spending': 228,\n",
              " 'hours': 229,\n",
              " 'distracted': 230,\n",
              " 'state': 231,\n",
              " 'hoping': 232,\n",
              " 'continue': 233,\n",
              " 'this': 234,\n",
              " 'momentum': 235,\n",
              " 'tomorrow': 236}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kECGfgDVFxlW",
        "outputId": "453a2de2-1f9b-48e3-8c83-c25fbcb03f24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "237"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "0OpuqKL-F04b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "\n",
        "  numerical_sentence = []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentence"
      ],
      "metadata": {
        "id": "gcXw1Da_GYMN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))"
      ],
      "metadata": {
        "id": "vHzneL0zGZ8F"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numerical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bajMAxdXGcTj",
        "outputId": "617f71f0-b987-4848-ee55-4e826a2dc270"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "RLhOjzpdGeLL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59JO02CzGgNm",
        "outputId": "1d8f79d4-d02a-41b8-b0d5-44fa90b637e5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "388"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xak7fGxGGiJL",
        "outputId": "34e8bb8f-0331-4126-fa96-b50b7e402971"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJaX6vfiGj9Q",
        "outputId": "5bb4ff86-7f31-4434-a324-a00c5a0d8d18"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuzlzhRRGmOO",
        "outputId": "017e5bb5-1914-449e-8884-3d79c8e0fabc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "\n",
        "  padded_training_sequence.append([0]*(max(len_list) - len(sequence)) + sequence)"
      ],
      "metadata": {
        "id": "uMcTn00tG6r6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St-UeeODG89P",
        "outputId": "f1a3139e-b1f0-49b7-9dfe-58dedb8238c2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ],
      "metadata": {
        "id": "XXCK-9WtG-Wu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCY0w6I7HBmo",
        "outputId": "ee0ee6e1-e64d-42af-a483-3e20688e8459"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   2,   3,   4],\n",
              "        ...,\n",
              "        [  0,   0, 210,  ..., 233, 234, 235],\n",
              "        [  0, 210,  19,  ..., 234, 235, 236],\n",
              "        [210,  19,   8,  ..., 235, 236,   7]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "mxcI2cFxHDVK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "3PUmrsOfHFIy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)\n",
        "len(dataset)\n",
        "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)"
      ],
      "metadata": {
        "id": "QZMuIk3yHHa1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "ufzU0u_jHPCo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "VcAcDmw7HRdG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "qK1wSSTuHTKr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQIOoTA4HVDt",
        "outputId": "21b176d4-6a70-40ba-a8ca-164627eca4a0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(237, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=237, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "SWh0elE4HWkS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch_x, batch_y in dataloader:\n",
        "\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfFM7o-7HZ7B",
        "outputId": "29c7d5c7-ccc7-4e2c-935d-d1dfe7b7df68"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 71.0811\n",
            "Epoch: 2, Loss: 68.7505\n",
            "Epoch: 3, Loss: 65.6838\n",
            "Epoch: 4, Loss: 61.3218\n",
            "Epoch: 5, Loss: 57.4958\n",
            "Epoch: 6, Loss: 52.4783\n",
            "Epoch: 7, Loss: 46.7326\n",
            "Epoch: 8, Loss: 43.1646\n",
            "Epoch: 9, Loss: 38.4152\n",
            "Epoch: 10, Loss: 34.4034\n",
            "Epoch: 11, Loss: 29.7990\n",
            "Epoch: 12, Loss: 27.1505\n",
            "Epoch: 13, Loss: 23.6227\n",
            "Epoch: 14, Loss: 20.9314\n",
            "Epoch: 15, Loss: 18.1288\n",
            "Epoch: 16, Loss: 15.9658\n",
            "Epoch: 17, Loss: 13.9684\n",
            "Epoch: 18, Loss: 12.5863\n",
            "Epoch: 19, Loss: 11.2421\n",
            "Epoch: 20, Loss: 10.1822\n",
            "Epoch: 21, Loss: 8.7757\n",
            "Epoch: 22, Loss: 7.7974\n",
            "Epoch: 23, Loss: 7.2362\n",
            "Epoch: 24, Loss: 6.2381\n",
            "Epoch: 25, Loss: 5.7470\n",
            "Epoch: 26, Loss: 5.2338\n",
            "Epoch: 27, Loss: 4.7310\n",
            "Epoch: 28, Loss: 4.7665\n",
            "Epoch: 29, Loss: 4.3034\n",
            "Epoch: 30, Loss: 3.8597\n",
            "Epoch: 31, Loss: 3.6221\n",
            "Epoch: 32, Loss: 3.3359\n",
            "Epoch: 33, Loss: 3.1942\n",
            "Epoch: 34, Loss: 2.9897\n",
            "Epoch: 35, Loss: 2.8324\n",
            "Epoch: 36, Loss: 2.6613\n",
            "Epoch: 37, Loss: 2.5318\n",
            "Epoch: 38, Loss: 2.6085\n",
            "Epoch: 39, Loss: 2.3235\n",
            "Epoch: 40, Loss: 2.2808\n",
            "Epoch: 41, Loss: 2.3414\n",
            "Epoch: 42, Loss: 2.0885\n",
            "Epoch: 43, Loss: 2.4662\n",
            "Epoch: 44, Loss: 2.0017\n",
            "Epoch: 45, Loss: 1.8810\n",
            "Epoch: 46, Loss: 1.7432\n",
            "Epoch: 47, Loss: 1.7035\n",
            "Epoch: 48, Loss: 1.6076\n",
            "Epoch: 49, Loss: 1.5378\n",
            "Epoch: 50, Loss: 1.5220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "\n",
        "def prediction(model, vocab, text):\n",
        "\n",
        "  # tokenize\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "  # text -> numerical indices\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "  # padding\n",
        "  padded_text = torch.tensor([0] * (61 - len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(padded_text)\n",
        "\n",
        "  # predicted index\n",
        "  value, index = torch.max(output, dim=1)\n",
        "\n",
        "  # merge with text\n",
        "  return text + \" \" + list(vocab.keys())[index]\n",
        "\n"
      ],
      "metadata": {
        "id": "t1Eom6J0Hjq3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"Today was a\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "    output_text = prediction(model, vocab, input_text)\n",
        "    print(output_text)\n",
        "    input_text = output_text\n",
        "    time.sleep(0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnxkbgV7HsQd",
        "outputId": "5af5a909-2357-4e99-a780-30b0f252de48"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today was a surprisingly\n",
            "Today was a surprisingly productive\n",
            "Today was a surprisingly productive day\n",
            "Today was a surprisingly productive day .\n",
            "Today was a surprisingly productive day . .\n",
            "Today was a surprisingly productive day . . hoping\n",
            "Today was a surprisingly productive day . . hoping to\n",
            "Today was a surprisingly productive day . . hoping to continue\n",
            "Today was a surprisingly productive day . . hoping to continue this\n",
            "Today was a surprisingly productive day . . hoping to continue this momentum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "xQ86pGkoH4xw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients\n",
        "        for batch_x, batch_y in dataloader1:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # Get the predicted word indices\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Compare with actual labels\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCtZW5xuH8kQ",
        "outputId": "0a07f66f-441e-407e-c9cc-48d44060af46"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 97.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6VlFgd_H-bj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}